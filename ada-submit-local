#!/usr/bin/env bash
# Submit CS416 PA5 programs as a job to ada. This script runs a Spark program on a single node using
# all of the available cores

# Set SLURM options (you should not need to change these)
#SBATCH --job-name=pa5                          # Job name
#SBATCH --output=pa5-%j.out                     # Name for output log file (%j is job ID)
#SBATCH --cpus-per-task=36                      # Cores per task
#SBATCH --partition=standard                    # Partition (queue) 
#SBATCH --time=03:00:00                         # Time limit hrs:min:sec

# Create scratch directory if it doesn't exist
mkdir -m 755 -p $SCRATCH

# DONT MODIFY THE SCRIPT ABOVE THIS LINE

echo -e "\n# Run Results -------------------------"

# Don't modify the driver memory, or conf operations, these are needed for correct
# and efficient execution on ada
spark-submit \
  --driver-memory 84G \
  --conf spark.local.dir=$SCRATCH \
  --master 'local[*]' \
  wordcount.py \
  "file://${PWD}/test/hanselandgretel.txt" 

# Other wordcount files
# "file://${TEXTS}/gutenberg-small.txt" 
# "file://${TEXTS}/gutenberg-all.txt" 

# The use of the file URL makes it explicit that these are local files. The ${TEXTS} substitutes
# the TEXTS environment variable into the path.

# Example command for pagerank
# spark-submit \
#   --driver-memory 84G \
#   --conf spark.local.dir=$SCRATCH \
#   --master 'local[*]' \
#   pagerank.py \
#   "file://${PWD}/test/small_graph.txt" \
#   100

# Other graph files
# "file://${PWD}/test/benchmark_graph.txt" 